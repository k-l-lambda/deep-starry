{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a default checkpoint\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "#config = Configuration.createOrLoad('configs/testencoder.yaml')\n",
    "config = Configuration.createOrLoad('training/melody/20220601-matchjointer-raw')\n",
    "model = loadModel(config['model'])\n",
    "\n",
    "# initialize parameters\n",
    "for p in model.parameters():\n",
    "\tif p.dim() > 1:\n",
    "\t\ttorch.nn.init.xavier_uniform_(p)\n",
    "\n",
    "torch.save({'model': model.state_dict()}, config.localPath('test.chkpt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[1., 2., 3., 4.]]])\n",
      "out: tensor([[[-1.2304, -0.1907, -0.1379,  1.5591]]])\n"
     ]
    }
   ],
   "source": [
    "# deduce test\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "config = Configuration.createOrLoad('training/melody/20220526-testencoder')\n",
    "model = loadModel(config['model'])\n",
    "\n",
    "checkpoint = torch.load(config.localPath(config['best']), map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tinput = torch.tensor([1, 2, 3, 4], dtype=torch.float32).reshape((1, 1, 4))\n",
    "\tprint('input:', input)\n",
    "\toutput = model(input)\n",
    "\tprint('out:', output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching: (tensor([[[1., 1.],\n",
      "         [1., 1.]]]), tensor([[[ 0.7071, -0.7071],\n",
      "         [ 0.7071, -0.7071]]]), tensor([[[ 0.7071,  0.7071],\n",
      "         [-0.7071, -0.7071]]]))\n"
     ]
    }
   ],
   "source": [
    "# MatchJointerRaw test\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "config = Configuration.createOrLoad('training/melody/20220601-matchjointer-raw')\n",
    "model = loadModel(config['model'])\n",
    "\n",
    "checkpoint = torch.load(config.localPath(config['best']), map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tc = torch.tensor([[[1, -1], [2, -2]]], dtype=torch.float32)\n",
    "\ts = torch.tensor([[[0, 0], [0, 0]]], dtype=torch.float32)\n",
    "\tmatching = model(c, s)\n",
    "\tprint('matching:', matching)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching: tensor([[[0.2726, 0.2509, 0.2567],\n",
      "         [0.2726, 0.2509, 0.2566],\n",
      "         [0.2725, 0.2509, 0.2566]]])\n"
     ]
    }
   ],
   "source": [
    "# MatchJointer1 test\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "config = Configuration.createOrLoad('training/melody/20220609-matchjointer1-test')\n",
    "model = loadModel(config['model'])\n",
    "\n",
    "checkpoint = torch.load(config.localPath(config['best']), map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tc = (torch.tensor([[0, 1, 2]], dtype=torch.float32), torch.tensor([[60, 62, 64]], dtype=torch.long), torch.tensor([[0.4, 0.5, 0.6]], dtype=torch.float32))\n",
    "\ts = (torch.tensor([[0, 1, 2]], dtype=torch.float32), torch.tensor([[60, 62, 64]], dtype=torch.long), torch.tensor([[0.4, 0.5, 0.6]], dtype=torch.float32))\n",
    "\tmatching, vc, vs = model(*c, *s)\n",
    "\tprint('matching:', matching)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x : Float(1, 3, strides=[3, 1], requires_grad=0, device=cpu)):\n",
      "  %y : Float(1, 9, strides=[9, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1](%x, %x, %x) # <ipython-input-22-b754483d1ad1>:14:0\n",
      "  return (%y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze operation\n",
    "import torch\n",
    "\n",
    "\n",
    "class TestModel(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t#return x.unsqueeze(-1).repeat(1, 1, 3)\n",
    "\t\t#return x.repeat(1, 3)\n",
    "\t\t#return x.unsqueeze(-1).tile((1, 1, 3))\n",
    "\t\t#return torch.tile(x.unsqueeze(-1), (1, 1, 3))\n",
    "\t\treturn torch.cat([x]*3, dim=-1)\n",
    "\n",
    "\n",
    "model = TestModel()\n",
    "\n",
    "scriptedm = torch.jit.script(model)\n",
    "scriptedm.save('./test.pt')\n",
    "\n",
    "torch.onnx.export(model, (torch.zeros(1,3, dtype=torch.float32),), './test.onnx',\n",
    "\tverbose=True,\n",
    "\tinput_names=('x',),\n",
    "\toutput_names=('y',),\n",
    "\topset_version=12)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
