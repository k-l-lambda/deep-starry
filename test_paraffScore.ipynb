{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding measures: 100%|██████████| 168/168 [00:00<00:00, 24949.30it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 5318.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ph_id torch.Size([2, 256])\n",
      "ph_f_num torch.Size([2, 256])\n",
      "ph_b_num torch.Size([2, 256])\n",
      "ph_summary torch.Size([2, 256, 256])\n",
      "ph_body_mask torch.Size([2, 256])\n",
      "ph_next_mask torch.Size([2, 256])\n",
      "input_ids torch.Size([2, 512])\n",
      "output_ids torch.Size([2, 512])\n",
      "body_mask torch.Size([2, 512])\n",
      "position torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-test.yaml', volatile=True)\n",
    "data, = loadDataset(config, data_dir=DATA_DIR, splits='9/10')\n",
    "\n",
    "it = iter(data)\n",
    "batch = next(it)\n",
    "\n",
    "for k in batch:\n",
    "\tprint(k, batch[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "batch = next(it)\n",
    "\n",
    "ph_mask = batch['ph_id'] != 0\n",
    "ph_mask[1:] = False\n",
    "w_mask = batch['input_ids'] >= 0\n",
    "w_mask[1:] = False\n",
    "\n",
    "ph = '\\n'.join([\n",
    "\t','.join(map(str, batch['ph_id'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_f_num'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_b_num'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_summary'][ph_mask].mean(dim=-1).tolist())),\n",
    "\t','.join(map(str, batch['ph_body_mask'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_next_mask'][ph_mask].tolist())),\n",
    "])\n",
    "with open('./test/phases.csv', 'w') as phases:\n",
    "    phases.write(ph)\n",
    "\n",
    "def id2word (id):\n",
    "    return data.dataset.measure.tokens[id]\n",
    "\n",
    "w = '\\n'.join([\n",
    "\t','.join(map(id2word, batch['input_ids'][w_mask].tolist())),\n",
    "\t','.join(map(id2word, batch['output_ids'][w_mask].tolist())),\n",
    "\t','.join(map(str, batch['body_mask'][w_mask].tolist())),\n",
    "\t','.join(map(str, batch['position'][w_mask].tolist())),\n",
    "])\n",
    "with open('./test/words.csv', 'w') as phases:\n",
    "    phases.write(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load paragraphs: 100%|██████████| 136/136 [00:00<00:00, 15815.28it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 7476.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9.2181, grad_fn=<AddBackward0>),\n",
       " {'acc': 0.0, 'latent_l2': 0.9999990463256836})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.7760, grad_fn=<AddBackward0>),\n",
       " {'acc': 0.0,\n",
       "  'latent_l2': 0.9999991655349731,\n",
       "  'error': 1.0,\n",
       "  'error_zero_latent': 1.0,\n",
       "  'error_no_primer': 1.0,\n",
       "  'error_zero_latent_no_primer': 1.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load paragraphs: 100%|██████████| 136/136 [00:00<00:00, 23851.20it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 17689.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.6464, grad_fn=<NllLossBackward>), {'acc': 0.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SeqDecoderBase\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-decoder-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-decoder-test.yaml')\n",
    "torch.save({'model': model.deducer.state_dict()}, config.localPath('untraied.chkpt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvinxu/work/deep-starry-paraff/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Encoding measures: 100%|██████████| 168/168 [00:00<00:00, 23701.42it/s]\n",
      "Load paragraphs: 100%|██████████| 136/136 [00:00<00:00, 16195.60it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 8536.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.7918, grad_fn=<AddBackward0>),\n",
       " {'acc': 0.0, 'latent_l2': 0.9999989867210388})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PhaseGen - lora decoder\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-phaselora-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvinxu/work/deep-starry-paraff/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 9784.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ph_id torch.Size([2, 256])\n",
      "ph_f_num torch.Size([2, 256])\n",
      "ph_b_num torch.Size([2, 256])\n",
      "ph_summary torch.Size([2, 256, 256])\n",
      "ph_body_mask torch.Size([2, 256])\n",
      "ph_next_mask torch.Size([2, 256])\n",
      "input_ids torch.Size([2, 512])\n",
      "output_ids torch.Size([2, 512])\n",
      "body_mask torch.Size([2, 512])\n",
      "position torch.Size([2, 512])\n",
      "tg_id torch.Size([2, 512])\n",
      "tg_staff torch.Size([2, 512])\n",
      "tg_x torch.Size([2, 512])\n",
      "tg_y torch.Size([2, 512])\n",
      "tg_sy1 torch.Size([2, 512])\n",
      "tg_sy2 torch.Size([2, 512])\n",
      "tg_confidence torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset with timewise graph\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "print('.')\t# workaround print bug\n",
    "\n",
    "config = Configuration.create('configs/paraff-graph-test.yaml', volatile=True)\n",
    "data, = loadDataset(config, data_dir=DATA_DIR, splits='9/10')\n",
    "\n",
    "it = iter(data)\n",
    "batch = next(it)\n",
    "\n",
    "for k in batch:\n",
    "\tprint(k, batch[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvinxu/work/deep-starry-paraff/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Load paragraphs: 100%|██████████| 136/136 [00:00<00:00, 19079.05it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 10163.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.4621, grad_fn=<NllLossBackward0>), {'acc': 0.321739137172699})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GraphParaffEncoder\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-graph-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.7169, grad_fn=<NllLossBackward0>),\n",
       " {'acc': 0.022346368059515953,\n",
       "  'error': 0.9776536226272583,\n",
       "  'error_zero_latent': 0.9776536226272583,\n",
       "  'error_no_primer': 0.9776536226272583,\n",
       "  'error_zero_latent_no_primer': 0.9776536226272583})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvinxu/work/deep-starry-paraff/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Load paragraphs: 100%|██████████| 208/208 [00:00<00:00, 10095.30it/s]\n",
      "Load paragraphs: 100%|██████████| 33/33 [00:00<00:00, 17795.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.7787, grad_fn=<NllLossBackward0>), {'acc': 0.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GraphParaffTranslator\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-graph_trans-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load paragraphs: 100%|██████████| 208/208 [00:00<00:00, 7101.76it/s]\n",
      "Load paragraphs: 100%|██████████| 33/33 [00:00<00:00, 6532.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(4.8810, grad_fn=<NllLossBackward0>), {'acc': 0.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GraphParaffTranslator with position\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-graph_trans-pos-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding measures: 100%|██████████| 504/504 [00:00<00:00, 27431.89it/s]\n",
      "Load paragraphs: 100%|██████████| 208/208 [00:00<00:00, 18019.15it/s]\n",
      "Load paragraphs: 100%|██████████| 33/33 [00:00<00:00, 12120.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.0004, grad_fn=<MseLossBackward0>), {'acc': 0.32967033982276917})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GraphParaffSummaryEncoder\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-graph_sum-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.8664, grad_fn=<NllLossBackward0>),\n",
       " {'acc': 0.0,\n",
       "  'acc_boundary': 0.0,\n",
       "  'error': 1.0,\n",
       "  'error_zero_latent': 1.0,\n",
       "  'error_no_primer': 1.0,\n",
       "  'error_zero_latent_no_primer': 1.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
