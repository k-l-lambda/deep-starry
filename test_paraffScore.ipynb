{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding measures: 100%|██████████| 42/42 [00:02<00:00, 15.77it/s]\n",
      "Load paragraphs: 100%|██████████| 164/164 [00:00<00:00, 25722.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ph_id torch.Size([2, 256])\n",
      "ph_f_num torch.Size([2, 256])\n",
      "ph_b_num torch.Size([2, 256])\n",
      "ph_summary torch.Size([2, 256, 256])\n",
      "ph_body_mask torch.Size([2, 256])\n",
      "ph_next_mask torch.Size([2, 256])\n",
      "input_ids torch.Size([2, 512])\n",
      "output_ids torch.Size([2, 512])\n",
      "body_mask torch.Size([2, 512])\n",
      "position torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-test.yaml', volatile=True)\n",
    "data, = loadDataset(config, data_dir=DATA_DIR, splits='*0/1')\n",
    "\n",
    "it = iter(data)\n",
    "batch = next(it)\n",
    "\n",
    "for k in batch:\n",
    "\tprint(k, batch[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "batch = next(it)\n",
    "\n",
    "ph_mask = batch['ph_id'] != 0\n",
    "ph_mask[1:] = False\n",
    "w_mask = batch['input_ids'] != 0\n",
    "w_mask[1:] = False\n",
    "\n",
    "ph = '\\n'.join([\n",
    "\t','.join(map(str, batch['ph_id'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_f_num'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_b_num'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_summary'][ph_mask].mean(dim=-1).tolist())),\n",
    "\t','.join(map(str, batch['ph_body_mask'][ph_mask].tolist())),\n",
    "\t','.join(map(str, batch['ph_next_mask'][ph_mask].tolist())),\n",
    "])\n",
    "with open('./test/phases.csv', 'w') as phases:\n",
    "    phases.write(ph)\n",
    "\n",
    "def id2word (id):\n",
    "    return data.dataset.measure.tokens[id]\n",
    "\n",
    "w = '\\n'.join([\n",
    "\t','.join(map(id2word, batch['input_ids'][w_mask].tolist())),\n",
    "\t','.join(map(id2word, batch['output_ids'][w_mask].tolist())),\n",
    "\t','.join(map(str, batch['body_mask'][w_mask].tolist())),\n",
    "\t','.join(map(str, batch['position'][w_mask].tolist())),\n",
    "])\n",
    "with open('./test/words.csv', 'w') as phases:\n",
    "    phases.write(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding measures: 100%|██████████| 42/42 [00:02<00:00, 15.75it/s]\n",
      "Load paragraphs: 100%|██████████| 136/136 [00:00<00:00, 24232.17it/s]\n",
      "Load paragraphs: 100%|██████████| 9/9 [00:00<00:00, 17664.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(5.9831, grad_fn=<AddBackward0>),\n",
       " {'acc': 0.21904762089252472,\n",
       "  'latent_l2': tensor(1.0000, grad_fn=<MeanBackward0>)})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "import os\n",
    "\n",
    "from starry.utils.config import Configuration\n",
    "from starry.utils.dataset_factory import loadDataset\n",
    "from starry.utils.model_factory import loadModel\n",
    "\n",
    "\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "\n",
    "config = Configuration.create('configs/paraff-score-test.yaml', volatile=True)\n",
    "train, val = loadDataset(config, data_dir=DATA_DIR, device='cpu')\n",
    "model = loadModel(config['model'], postfix='Loss')\n",
    "\n",
    "it = iter(train)\n",
    "\n",
    "batch = next(it)\n",
    "loss, metric = model(batch)\n",
    "\n",
    "loss, metric\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
